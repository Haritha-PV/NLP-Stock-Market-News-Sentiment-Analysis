# -*- coding: utf-8 -*-
"""Clustering Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/166_3U14nKwmb4R2cO8582BnFgRvj4kvt
"""

pip install vaderSentiment

"""# Importing required libraries"""

import numpy as np
import pandas as pd
from sklearn.cluster import DBSCAN, MiniBatchKMeans
from sklearn.decomposition import TruncatedSVD
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
from nltk.corpus import stopwords
import nltk
import re
import sqlite3
from sklearn.utils import shuffle
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import silhouette_samples
from wordcloud import WordCloud

# Ensure necessary NLTK downloads
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('punkt_tab')

"""## Connecting to Google Drive"""

from google.colab import drive
drive.mount('/content/drive')

# Database connection and reading data from the database
conn = sqlite3.connect('/content/drive/MyDrive/Inttrvu/Database.db')

df = pd.read_sql_query('Select * from New_Delhi_Reviews' , conn)

df

"""# Text Data Cleaning"""

# Removing stopwords and unnecessary characters from the reviews
stop_words = set(stopwords.words('english'))

def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    words = nltk.word_tokenize(text)
    return ' '.join([word for word in words if word not in stop_words])

# Applying the clean_text function to each review
df['cleaned_review'] = df['review_full'].apply(clean_text)

#Reducing dataset size for efficient processing
df_sampled = shuffle(df, random_state=42).iloc[:2000]
print(f"Data size after sampling: {df_sampled.shape[0]} rows")

"""# Feature Extraction from Text Data"""

# TF-IDF Vectorization,Using TF-IDF to transform the cleaned reviews into numerical features
tfidf = TfidfVectorizer(max_features=5000)
X_sampled = tfidf.fit_transform(df_sampled['cleaned_review'])

# Dimensionality reduction using TruncatedSVD
svd = TruncatedSVD(n_components=5, random_state=42)  # Use only 10 components
X_reduced = svd.fit_transform(X_sampled)

"""# Clustering and Number of Clusters Identified"""

#Applying MiniBatchKMeans to perform clustering
kmeans = MiniBatchKMeans(n_clusters=25, batch_size=500, random_state=42)
kmeans_labels = kmeans.fit_predict(X_reduced)

# Assigning cluster labels to the DataFrame
df_sampled['cluster'] = kmeans_labels

# Silhouette Score to evaluate the clustering
sil_score = silhouette_score(X_reduced, kmeans_labels)
print(f"Silhouette Score: {sil_score}")

# Displaying reviews in each cluster (Top Themes)
for cluster in range(25):
    print(f"\nTop Themes for Cluster {cluster}:")
    cluster_reviews = df_sampled[df_sampled['cluster'] == cluster]['review_full']
    if len(cluster_reviews) > 0:
        print(" | ".join(cluster_reviews.sample(min(3, len(cluster_reviews))).values))  # Show up to 3 reviews per cluster
    else:
        print("No reviews in this cluster.")

"""# Sentiment Analysis using VADER"""

# Initialize the sentiment analyzer
analyzer = SentimentIntensityAnalyzer()

# Function to classify review sentiment
def get_sentiment(text):
    sentiment = analyzer.polarity_scores(text)
    return 'positive' if sentiment['compound'] > 0 else 'negative'

# Add sentiment column to the DataFrame
df_sampled['sentiment'] = df_sampled['review_full'].apply(get_sentiment)

# Show Positive Reviews for Each Cluster
for cluster in range(25):
    print(f"\nPositive Reviews for Cluster {cluster}:")
    positive_reviews = df_sampled[(df_sampled['cluster'] == cluster) & (df_sampled['sentiment'] == 'positive')]

    if len(positive_reviews) > 0:
        print(positive_reviews['review_full'].sample(min(3, len(positive_reviews))).values)  # Show up to 3 positive reviews
    else:
        print("No positive reviews in this cluster.")

"""# Visualizing the Clusters"""

# Visualizing the clusters using a 2D scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=kmeans_labels, cmap='viridis', s=10, alpha=0.7)
plt.title("Clusters Visualization")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.colorbar(label="Cluster ID")
plt.show()

# Create a WordCloud for each cluster
for cluster in range(25):
    print(f"Word Cloud for Cluster {cluster}")
    cluster_reviews = df_sampled[df_sampled['cluster'] == cluster]['cleaned_review']
    text = ' '.join(cluster_reviews)
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

    plt.figure(figsize=(10, 6))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.title(f"Word Cloud for Cluster {cluster}")
    plt.axis('off')
    plt.show()

# Compute the silhouette scores for each sample
silhouette_vals = silhouette_samples(X_reduced, kmeans_labels)

# Create the silhouette plot
fig, ax = plt.subplots(figsize=(10, 6))
y_lower, y_upper = 0, 0

for i in range(25):  # 25 clusters
    cluster_silhouette_vals = silhouette_vals[kmeans_labels == i]
    cluster_silhouette_vals.sort()
    y_upper = y_lower + len(cluster_silhouette_vals)
    ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette_vals, alpha=0.7)
    ax.text(-0.05, (y_lower + y_upper) / 2, f'Cluster {i}', fontsize=12)
    y_lower = y_upper

ax.set_title("Silhouette Plot for Each Cluster")
ax.set_xlabel("Silhouette Score")
ax.set_ylabel("Cluster ID")
plt.show()

"""# Calculate the Percentage of Positive and Negative Reviews"""

# Calculate the count of positive and negative reviews
positive_count = df_sampled[df_sampled['sentiment'] == 'positive'].shape[0]
negative_count = df_sampled[df_sampled['sentiment'] == 'negative'].shape[0]

# Calculate the total number of reviews
total_reviews = df_sampled.shape[0]

# Calculate the percentage of positive and negative reviews
positive_percentage = (positive_count / total_reviews) * 100
negative_percentage = (negative_count / total_reviews) * 100

# Display the results
print(f"Total Reviews: {total_reviews}")
print(f"Positive Reviews: {positive_count} ({positive_percentage:.2f}%)")
print(f"Negative Reviews: {negative_count} ({negative_percentage:.2f}%)")

"""# Top Positive and Negative Themes"""

# Function to get top themes for a given set of reviews
def get_top_terms(tfidf, reviews, n=10):
    vectorized_reviews = tfidf.transform(reviews)
    terms = tfidf.get_feature_names_out()
    top_terms_indices = vectorized_reviews.toarray().sum(axis=0).argsort()[-n:][::-1]
    return ", ".join(terms[top_terms_indices])

# Iterate through clusters and find top positive and negative themes
for cluster in range(25):  # Assuming there are 25 clusters
    print(f"\nTop Positive and Negative Themes for Cluster {cluster}:")

    # Get positive reviews for the current cluster
    positive_reviews = df_sampled[(df_sampled['cluster'] == cluster) & (df_sampled['sentiment'] == 'positive')]['cleaned_review']

    # Get negative reviews for the current cluster
    negative_reviews = df_sampled[(df_sampled['cluster'] == cluster) & (df_sampled['sentiment'] == 'negative')]['cleaned_review']

    if len(positive_reviews) > 0:
        print(f"\nTop Positive Themes for Cluster {cluster}:")
        positive_top_terms = get_top_terms(tfidf, positive_reviews)
        print(positive_top_terms)
    else:
        print(f"No positive reviews in Cluster {cluster}")

    if len(negative_reviews) > 0:
        print(f"\nTop Negative Themes for Cluster {cluster}:")
        negative_top_terms = get_top_terms(tfidf, negative_reviews)
        print(negative_top_terms)
    else:
        print(f"No negative reviews in Cluster {cluster}")

"""# Prediction"""

# List of new reviews
new_reviews = [
    "The food was terrible, I didn't like it at all.",
    "Absolutely fantastic! Loved the flavors and the texture.",
    "Not worth the price, I expected better."
]

# Loop through reviews and predict sentiment
for review in new_reviews:
    sentiment_prediction = get_sentiment(review)
    print(f"Review: {review}")
    print(f"Sentiment: {sentiment_prediction}\n")

# Example review
new_review = "I love the taste of the biryani, it's amazing!"

# Predict sentiment
sentiment_prediction = get_sentiment(new_review)
print(f"Sentiment of the review: {sentiment_prediction}")