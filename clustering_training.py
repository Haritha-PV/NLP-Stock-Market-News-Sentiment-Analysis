# -*- coding: utf-8 -*-
"""Clustering Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/166_3U14nKwmb4R2cO8582BnFgRvj4kvt
"""

import pandas as pd
import sqlite3
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import matplotlib.pyplot as plt
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')

from google.colab import drive
drive.mount('/content/drive')

conn = sqlite3.connect('/content/drive/MyDrive/Inttrvu/Database.db')

df = pd.read_sql_query('Select * from New_Delhi_Reviews' , conn)

df

# Text cleaning function
def clean_text(text):
    # Convert to lowercase
    text = text.lower()
    # Remove punctuation, numbers, and special characters
    text = re.sub(r'[^a-z\s]', '', text)
    # Tokenize the text
    words = word_tokenize(text)
    # Remove stopwords and lemmatize
    stop_words = set(stopwords.words('english'))
    lemmatizer = WordNetLemmatizer()
    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]
    return ' '.join(words)

# Apply the cleaning function
df['cleaned_review'] = df['review_full'].apply(clean_text)

# 4. Feature extraction using TF-IDF
tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features for better performance
X = tfidf_vectorizer.fit_transform(df['cleaned_review'])

print(df.info())  # Check data types of each column
print(df.head())  # Display the first few rows of the dataset

from sklearn.feature_extraction.text import TfidfVectorizer

# Create a TF-IDF Vectorizer
tfidf = TfidfVectorizer(stop_words='english')

# Fit and transform the cleaned review text data
tfidf_matrix = tfidf.fit_transform(df['cleaned_review'])

print(tfidf_matrix.shape)  # Check the resulting matrix dimensions

# Step 2: Apply KMeans clustering to the TF-IDF matrix
# Initialize KMeans with a chosen number of clusters (e.g., 3)
kmeans = KMeans(n_clusters=3, random_state=42)

# Fit the KMeans model
kmeans.fit(tfidf_matrix)

# Step 3: Check the cluster assignments for each review
df['Cluster'] = kmeans.labels_

# Display the resulting clusters
print(df[['review_full', 'Cluster']])

inertia = []  # Reset the list
for k in range(2, 11):  # Ensure range matches the plot
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(df)
    inertia.append(kmeans.inertia_)

for k in range(2, 11):  # Test for K values from 2 to 10
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_reduced)  # Use X_reduced instead of X
    inertia.append(kmeans.inertia_)
    sil_scores.append(silhouette_score(X_reduced, kmeans.labels_))

print(len(inertia))  # Should print 9

print(len(range(2, 11)))  # Should print 9
print(len(inertia))

# Plot the Elbow Curve
plt.plot(range(2, 11), inertia, marker='o')
plt.title('Elbow Method for Optimal K')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Inertia')
plt.show()

# Plot the Silhouette Scores
plt.plot(range(2, 11), sil_scores, marker='o')
plt.title('Silhouette Score for Different K')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Silhouette Score')
plt.show()

# 6. Apply K-Means with the chosen number of clusters (e.g., K=4 based on Elbow/Silhouette)
k = 4  # Chosen after evaluation
kmeans = KMeans(n_clusters=k, random_state=42)
df['cluster'] = kmeans.fit_predict(X)

# 7. Analyze the top terms for each cluster (positive/negative themes)
terms = tfidf_vectorizer.get_feature_names_out()
for i in range(k):
    print(f"Cluster {i} Top Terms:")
    cluster_center = kmeans.cluster_centers_[i]
    sorted_terms_idx = cluster_center.argsort()[-10:][::-1]
    top_terms = [terms[idx] for idx in sorted_terms_idx]
    print(top_terms)

# 8. Identifying Positive and Negative Themes based on Clusters and Ratings
# Analyze the reviews in each cluster and determine positive/negative based on average ratings
for i in range(k):
    cluster_reviews = df[df['cluster'] == i]
    avg_rating = cluster_reviews['rating_review'].mean()
    print(f"Cluster {i} - Average Rating: {avg_rating}")
    if avg_rating >= 4:
        print(f"Cluster {i} is Positive")
    else:
        print(f"Cluster {i} is Negative")

# 9. Future Review Clustering (for new reviews)
def predict_cluster(new_review):
    cleaned_review = clean_text(new_review)
    new_vector = tfidf_vectorizer.transform([cleaned_review])
    cluster = kmeans.predict(new_vector)
    return cluster

# Example for predicting a new review
new_review = "This place is amazing with great service!"
cluster = predict_cluster(new_review)
print(f"The new review belongs to cluster {cluster[0]}")